{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from common import *\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "book = read_file('data/Strang-Linear Algebra.txt')\n",
    "chapter = OrderedDict(get_one_chapter_strang(7, book, subsections=True, \n",
    "                                      split=True, sentence_spliter=lambda ss: nlp(ss).sents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['Minima, Maxima, and Saddle Points', 'Tests for Positive Definiteness ', 'Singular Value Decomposition ', 'Minimum Principles ', 'The Finite Element Method '])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chapter.keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features for gap-fill question-generatable and informative sentences selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### FEATURES\n",
    "\n",
    "def get_tags(sentence):\n",
    "    return [token.tag_ for token in nlp(sentence)]\n",
    "\n",
    "def get_noun_adj_tokens(words):\n",
    "    return [token.lemma_ for token in nlp(words) \n",
    "            if token.pos_ == 'ADJ' or token.pos_ == 'NOUN']\n",
    "\n",
    "    \n",
    "# Informative \n",
    "def is_first_sentence(f, c):\n",
    "    return f == c\n",
    "\n",
    "\n",
    "def has_superlatives(curr):\n",
    "    pos_tags = get_tags(curr)\n",
    "    return 'JJR' in pos_tags or 'JJS' in pos_tags\n",
    "\n",
    "\n",
    "def has_abbreviation(curr):\n",
    "    is_abbr = lambda word: word.upper() == word and len(word) > 1\n",
    "    return any(is_abbr(x) for x in curr.split())\n",
    "\n",
    "\n",
    "def has_correct_ending(curr):\n",
    "    return curr[-1] in ['?', '.', '!']\n",
    "\n",
    "# Generative\n",
    "\n",
    "\n",
    "def relative_number_of_words(curr):\n",
    "    abs_n = abs(len(curr.split()) - 10)\n",
    "    return -abs_n if abs_n > 5 else abs_n\n",
    "\n",
    "\n",
    "def relative_index(i, doc_length):\n",
    "    abs_i = abs(i - doc_length/2)\n",
    "    return abs_i if abs_i > doc_length/4 else -abs_i\n",
    "\n",
    "\n",
    "def common_tokens_count(curr, title):\n",
    "    curr_tokens = get_noun_adj_tokens(curr)\n",
    "    title_tokens = get_noun_adj_tokens(title.lower())\n",
    "    \n",
    "    return sum([tok in curr_tokens for tok in title_tokens])\n",
    "\n",
    "\n",
    "def begins_with_discourse_connective(curr):\n",
    "    discource_connective = ['because', 'since', 'when', 'thus', \n",
    "                            'however', 'although', 'for example', \n",
    "                            'and', 'for instance', 'how', 'in other words',\n",
    "                            'therefore', 'up to this point']\n",
    "    curr = curr.lower()\n",
    "    return any(curr.startswith(x) for x in discource_connective)\n",
    "\n",
    "\n",
    "def nouns_number(curr):\n",
    "    return sum(x.pos_ == 'NOUN' for x in nlp(curr))\n",
    "\n",
    "\n",
    "def pronouns_number(curr):\n",
    "    return sum(x.pos_ == 'PRON' for x in nlp(curr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_weights = {\n",
    "    +4:lambda s, indx, title, first_s, doc_length:  is_first_sentence(s, first_s),\n",
    "    +1:lambda s, indx, title, first_s, doc_length:  has_superlatives(s),\n",
    "    +1:lambda s, indx, title, first_s, doc_length:  has_abbreviation(s),\n",
    "    +.5:lambda s, indx, title, first_s, doc_length:  relative_number_of_words(s),\n",
    "    +2:lambda s, indx, title, first_s, doc_length:  common_tokens_count(s, title),\n",
    "    -2:lambda s, indx, title, first_s, doc_length:  begins_with_discourse_connective(s),\n",
    "    +1:lambda s, indx, title, first_s, doc_length:  nouns_number(s),\n",
    "    -2.5:lambda s, indx, title, first_s, doc_length:  pronouns_number(s),\n",
    "    +0.01:lambda s, indx, title, first_s, doc_length:  relative_index(indx, doc_length),\n",
    "    +2:lambda s, indx, title, first_s, doc_length:  has_correct_ending(s)\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "def get_sentence_score(sentence, index, title, first_sentence, doc_length, weights):\n",
    "    return sum(key * weights[key](sentence, index, title, first_sentence, doc_length) \n",
    "               for key in weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.zeros(sum(len(chapter[x]) for x in chapter))\n",
    "global_indx = 0\n",
    "for key in chapter:\n",
    "    document = chapter[key]\n",
    "    title = key\n",
    "    doc_length = len(document)\n",
    "    first_sentence = document[0]\n",
    "    \n",
    "    for i, sentence in enumerate(document):\n",
    "        scores[global_indx] = get_sentence_score(\n",
    "                              sentence, i, title, first_sentence, \n",
    "                              doc_length, feature_weights)\n",
    "        global_indx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = OrderedDict((key, len(chapter[key])) for key in chapter)\n",
    "\n",
    "def get_sentence_index_in_document(doc_sent_indx, docs):\n",
    "    indexes =list(docs.values())\n",
    "    i = -1\n",
    "    prev = 0\n",
    "    while doc_sent_indx >= 0:\n",
    "        i += 1\n",
    "        prev = doc_sent_indx\n",
    "        doc_sent_indx -= indexes[i]\n",
    "    doc_name = list(docs.keys())[i]\n",
    "    return doc_name, prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting sentences with best scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Singular Value Decomposition \n",
      "A great matrix factorization has been saved for the end of the basic course.\n",
      "14.86\n",
      "\n",
      "Tests for Positive Definiteness \n",
      "Which symmetric matrices have the property that xTAx > 0 for all nonzero vectors\n",
      "13.23\n",
      "\n",
      "Tests for Positive Definiteness \n",
      "The two parts of this hook were linked by the chapter on determinants.\n",
      "11.44\n",
      "\n",
      "Tests for Positive Definiteness \n",
      "The previous section began with some hints about the signs of eigenvalues.\n",
      "11.2\n",
      "\n",
      "Tests for Positive Definiteness \n",
      "Elimination becomes fast, and the search for eigenvalues (by halving the intervals) becomes simple.\n",
      "11.15\n",
      "\n",
      "Tests for Positive Definiteness \n",
      "An example is the motion of two unequal masses in a line of springs: m1\n",
      "10.71\n",
      "\n",
      "Singular Value Decomposition \n",
      "The SVD is closely associated with the eigenvalue-eigenvector factorization QLQT of a positive definite matrix.\n",
      "10.32\n",
      "\n",
      "Tests for Positive Definiteness \n",
      "By the law of inertia, A has the same number of positive eigenvalues as D.\n",
      "10.29\n",
      "\n",
      "Minimum Principles \n",
      "1I am convinced that plants and people also develop in accordance with minimum principles.\n",
      "10.120000000000001\n",
      "\n",
      "Tests for Positive Definiteness \n",
      "All the pivots (without row exchanges) satisfy dk > 0. Proof.\n",
      "10.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ordered_scores = np.flip(np.argsort(scores))\n",
    "top_scores = ordered_scores[:10]\n",
    "\n",
    "top_sentences = []\n",
    "for s in top_scores:\n",
    "    doc_name, index = get_sentence_index_in_document(s, docs)\n",
    "    top_sentences.append((doc_name, index))\n",
    "    \n",
    "    print(doc_name)\n",
    "    print(chapter[doc_name][index])\n",
    "    print(scores[s])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {0: ['A great matrix factorization',\n",
       "              'the end',\n",
       "              'the basic course'],\n",
       "             1: ['Which symmetric matrices',\n",
       "              'the property',\n",
       "              'all nonzero vectors'],\n",
       "             2: ['The two parts', 'this hook', 'the chapter', 'determinants'],\n",
       "             3: ['The previous section',\n",
       "              'some hints',\n",
       "              'the signs',\n",
       "              'eigenvalues'],\n",
       "             4: ['Elimination', 'the search', 'eigenvalues', 'the intervals'],\n",
       "             5: ['An example',\n",
       "              'the motion',\n",
       "              'two unequal masses',\n",
       "              'a line',\n",
       "              'springs'],\n",
       "             6: ['The SVD',\n",
       "              'the eigenvalue-eigenvector factorization QLQT',\n",
       "              'a positive definite matrix'],\n",
       "             7: ['the law',\n",
       "              'inertia',\n",
       "              'A',\n",
       "              'the same number',\n",
       "              'positive eigenvalues'],\n",
       "             8: ['plants', 'people', 'accordance', 'minimum principles'],\n",
       "             9: ['All the pivots', 'row exchanges', 'Proof']})"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "key_list = defaultdict(lambda: list())\n",
    "\n",
    "for i, (doc_name, sent_i) in enumerate(top_sentences):\n",
    "    sent = chapter[doc_name][sent_i]\n",
    "    for chunk in nlp(sent).noun_chunks:\n",
    "        if check_wordset(chunk.text):\n",
    "            key_list[i].append(chunk.text)\n",
    "\n",
    "key_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_important_word(chunk):\n",
    "    importance_order = ['ADJ','NOUN', 'NUM']\n",
    "    for pos in importance_order:\n",
    "        for i in nlp(chunk):\n",
    "            if str(i.pos_) == pos:\n",
    "                return i.text\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ADV', 'NOUN', 'ADJ', 'SCONJ', 'NUM', 'CCONJ', 'NUM']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.pos_ for x in nlp('Even numbers such as 2 and 4')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'such'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_most_important_word('Even numbers such as 2 and 4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features for key selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_occurance(key, title):\n",
    "    return common_tokens_count(key, title)\n",
    "\n",
    "\n",
    "def document_occurance(key, doc):\n",
    "    total = 0\n",
    "    for s in doc:\n",
    "        total += common_tokens_count(key, s)\n",
    "    return total\n",
    "\n",
    "\n",
    "def get_depth_in_syntactic_tree(token, depth=0):\n",
    "    d = [get_depth_in_syntactic_tree(child, depth+1) for child in token.children]\n",
    "    d.append(0)\n",
    "    return max(d)\n",
    "    \n",
    "\n",
    "def depth_in_sentence(key, s):\n",
    "    most_imp = get_most_important_word(key)\n",
    "    for tok in nlp(s):\n",
    "        if str(tok.text) == most_imp:\n",
    "            return get_depth_in_syntactic_tree(tok)\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_key(key_list, sentence, doc, title):\n",
    "    scores = [title_occurance((key), title)  + \\\n",
    "              document_occurance((key), doc) +\n",
    "              depth_in_sentence((key), sentence)\n",
    "                  for key in key_list]\n",
    "    return key_list[scores.index(max(scores))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A great matrix factorization', 'the end', 'the basic course']\n",
      "['Which symmetric matrices', 'the property', 'all nonzero vectors']\n",
      "['The two parts', 'this hook', 'the chapter', 'determinants']\n",
      "['The previous section', 'some hints', 'the signs', 'eigenvalues']\n",
      "['Elimination', 'the search', 'eigenvalues', 'the intervals']\n",
      "['An example', 'the motion', 'two unequal masses', 'a line', 'springs']\n",
      "['The SVD', 'the eigenvalue-eigenvector factorization QLQT', 'a positive definite matrix']\n",
      "['the law', 'inertia', 'A', 'the same number', 'positive eigenvalues']\n",
      "['plants', 'people', 'accordance', 'minimum principles']\n",
      "['All the pivots', 'row exchanges', 'Proof']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {0: 'A great matrix factorization',\n",
       "             1: 'Which symmetric matrices',\n",
       "             2: 'determinants',\n",
       "             3: 'eigenvalues',\n",
       "             4: 'eigenvalues',\n",
       "             5: 'An example',\n",
       "             6: 'a positive definite matrix',\n",
       "             7: 'positive eigenvalues',\n",
       "             8: 'minimum principles',\n",
       "             9: 'All the pivots'})"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in key_list:\n",
    "    doc = chapter[top_sentences[i][0]]\n",
    "    doc = [i.lower() for i in doc]\n",
    "    s = doc[top_sentences[i][1]]\n",
    "    print(key_list[i])\n",
    "    key_list[i] = get_best_key(key_list[i], s, doc, top_sentences[i][0])\n",
    "key_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distractors selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\programdata\\anaconda3\\lib\\site-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from textblob) (3.4.5)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "from distractors_generation import get_distractors\n",
    "import spacy\n",
    "nlp_model = spacy.load(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a great matrix factorization has been saved for the end of the basic course.\n",
      "act\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'check_wordset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-157-cc310bf54a5c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtop_sentences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mdistractors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_distractors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnlp_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistractors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdistractors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mkey_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\QuizMaker\\distractors_generation.py\u001b[0m in \u001b[0;36mget_distractors\u001b[1;34m(chapter_sentences, key, key_sent, ner_model, num_distractors)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;31m#     scores_final = []\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;31m#     for cand, sent in zip(distractor_candidates, candidate_sentences):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m \u001b[1;31m#         if ((cand not in key and key not in cand and any(i for i in cand if i\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;31m#             not in key_sent)) or key_label == 'mtrx') and check_wordset(cand) and cand != key:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;31m#             sent_simil = sentence_similarity(key_sent, sent)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'check_wordset' is not defined"
     ]
    }
   ],
   "source": [
    "for i in key_list:\n",
    "    doc = chapter[top_sentences[i][0]]\n",
    "    doc = [i.lower() for i in doc]\n",
    "    s = doc[top_sentences[i][1]]\n",
    "    print(s)\n",
    "    distractors = get_distractors(doc, key_list[i].lower(), s, nlp_model, 4)\n",
    "    print(distractors[0], distractors[1][1])\n",
    "key_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "didnt find an entity in  matrix factorization\n",
      "didnt find an entity in  symmetric\n",
      "didnt find an entity in  determinants\n",
      "didnt find an entity in  eigenvalues\n",
      "didnt find an entity in  eigenvalues\n",
      "didnt find an entity in  an example\n",
      "didnt find an entity in  positive definite matrix\n",
      "didnt find an entity in  eigenvalues\n",
      "didnt find an entity in  minimum principles\n",
      "didnt find an entity in  pivots\n",
      "\n",
      "\n",
      "\n",
      "This is a LinearUp - automatically generated quiz\n",
      "\n",
      "\n",
      "A great __________ has been saved for the end of the basic course.\n",
      "(a) square\t(b) qs\t(c) step\t(d) matrix factorization\t\n",
      "\n",
      "Which __________ matrices have the property that xTAx > 0 for all nonzero vectors\n",
      "(a) definite\t(b) book\t(c) introduction\t(d) symmetric\t\n",
      "\n",
      "The two parts of this hook were linked by the chapter on __________.\n",
      "(a) numberss\t(b) eigenvaluess\t(c) purposess\t(d) determinants\t\n",
      "\n",
      "The previous section began with some hints about the signs of __________.\n",
      "(a) physicss\t(b) axess\t(c) determinantss\t(d) eigenvalues\t\n",
      "\n",
      "Elimination becomes fast, and the search for __________ (by halving the intervals) becomes simple.\n",
      "(a) axess\t(b) least-squaress\t(c) squaress\t(d) eigenvalues\t\n",
      "\n",
      "An example is the motion of two unequal masses in a line of springs: m1\n",
      "(a) definite\t(b) book\t(c) introduction\t(d) an example\t\n",
      "\n",
      "The SVD is closely associated with the eigenvalue-eigenvector factorization QLQT of a __________.\n",
      "(a) size\t(b) polar\t(c) real\t(d) positive definite matrix\t\n",
      "\n",
      "By the law of inertia, A has the same number of positive __________ as D.\n",
      "(a) applicationss\t(b) matricess\t(c) mathematics\t(d) eigenvalues\t\n",
      "\n",
      "1I am convinced that plants and people also develop in accordance with __________.\n",
      "(a) symmetrics\t(b) horizontals\t(c) firsts\t(d) minimum principles\t\n",
      "\n",
      "All the __________ (without row exchanges) satisfy dk > 0. Proof.\n",
      "(a) matricess\t(b) mathematics\t(c) problemss\t(d) pivots\t\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from quiz_generation import create_quiz   \n",
    "\n",
    "n = 10\n",
    "\n",
    "questions = []\n",
    "for i, (doc_name, sentence_index) in enumerate(top_sentences[:n]):\n",
    "    s = chapter[doc_name][sentence_index]\n",
    "    if key_list[i]:\n",
    "        distractors = get_distractors(chapter[doc_name], key_list[i].lower(), s.lower(), nlp_model, 3)\n",
    "        questions.append([s, distractors[1][1], distractors[0]])\n",
    "print(\"\\n\")\n",
    "print(create_quiz(questions, correct_answer=False, save=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
